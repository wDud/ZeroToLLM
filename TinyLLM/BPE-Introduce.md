# what's BPE?
    BPE（Byte-Pair Encoding）是一种基于字符的分词方法，最初用于数据压缩，后来被广泛应用于自然语言处理（NLP）中的分词任务。其核心思想是通过逐步合并语料中出现频率最高的字符对，形成新的子词，直到达到预定的词汇表大小。
## 算法步骤
 - 初始化：从每个单词的字符级分割开始，初始词汇表包含所有可能的字符。
 - 统计频率：对语料中所有字符对的出现频率进行统计。
 - 合并操作：找到最频繁的字符对，将其合并为一个新的子词，并更新词汇表。
 - 重复迭代：重复步骤2和3，直到达到预定的词汇表大小。
 - 生成模型文件：最终生成的词汇表被保存为分词模型文件，如tokenizer.model。
## 优点
    处理未登录词（OOV）：BPE能够将罕见的词分割为常见的子词，从而有效处理未登录词。
    灵活的词汇表大小：通过控制词汇表大小，BPE可以在模型大小和性能之间提供灵活的折中。
## 应用
    BPE广泛应用于多语言模型，如GPT-2和MarianMT，特别适合处理词形变化丰富的语言